# ğŸ“Š Grafana + Prometheus ëª¨ë‹ˆí„°ë§ ì„¤ì • ê°€ì´ë“œ

> CloudWatch ëŒ€ì‹  ì˜¤í”ˆì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§ ìŠ¤íƒìœ¼ë¡œ ì™„ì „í•œ observability êµ¬ì¶•

## ğŸ¯ **ì™œ Grafana + Prometheusì¸ê°€?**

### âœ… **ì••ë„ì ì¸ ì¥ì ë“¤**
- **ğŸ’° ë¬´ë£Œ**: CloudWatch ëŒ€ë¹„ ì›” ìˆ˜ë°±ë‹¬ëŸ¬ ì ˆì•½
- **ğŸ¨ ì•„ë¦„ë‹¤ìš´ ì‹œê°í™”**: ì„¸ê³„ì—ì„œ ê°€ì¥ ì˜ˆìœ ëŒ€ì‹œë³´ë“œ
- **âš¡ ì‹¤ì‹œê°„**: ì´ˆ ë‹¨ìœ„ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
- **ğŸ”— í†µí•©**: ëª¨ë“  ì‹œìŠ¤í…œì„ í•˜ë‚˜ì˜ ëŒ€ì‹œë³´ë“œì—ì„œ
- **ğŸš€ í™•ì¥ì„±**: ëŒ€ìš©ëŸ‰ ë©”íŠ¸ë¦­ ì²˜ë¦¬

### ğŸ“Š **ëª¨ë‹ˆí„°ë§í•  ì‹œìŠ¤í…œë“¤**
```mermaid
graph TB
    subgraph "Application Layer"
        A[Spring Boot App]
        A1[API Response Time]
        A2[Upload Success Rate]
        A3[Processing Queue Size]
    end

    subgraph "Infrastructure Layer"
        B[MySQL]
        C[Redis]
        D[Kafka]
        E[Docker Containers]
    end

    subgraph "AWS Layer"
        F[S3 Metrics]
        G[EventBridge Events]
    end

    A --> A1 & A2 & A3
    B --> B1[Connection Pool]
    C --> C1[Memory Usage]
    D --> D1[Consumer Lag]
    E --> E1[Resource Usage]

    Prometheus --> Grafana
    A1 & A2 & A3 & B1 & C1 & D1 & E1 --> Prometheus
```

---

## ğŸ—ï¸ **ì „ì²´ ì•„í‚¤í…ì²˜**

```yaml
version: '3.8'
services:
  # ê¸°ì¡´ ì„œë¹„ìŠ¤ë“¤
  mysql:
    # MySQL + mysql_exporter
  redis:
    # Redis + redis_exporter
  kafka:
    # Kafka + kafka_exporter

  # ëª¨ë‹ˆí„°ë§ ìŠ¤íƒ
  prometheus:
    # ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ë° ì €ì¥
  grafana:
    # ì‹œê°í™” ë° ì•ŒëŒ
  node-exporter:
    # ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­
  cadvisor:
    # ì»¨í…Œì´ë„ˆ ë©”íŠ¸ë¦­
```

---

## ğŸš€ **1ë‹¨ê³„: Docker Compose í™•ì¥**

### ê¸°ì¡´ docker-compose.ymlì— ì¶”ê°€

```yaml
# docker-compose.monitoring.yml
version: '3.8'

services:
  # ============================================
  # Prometheus - ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ë° ì €ì¥
  # ============================================
  prometheus:
    image: prom/prometheus:v2.45.0
    container_name: orakgaraki-prometheus
    restart: unless-stopped
    ports:
      - "${PROMETHEUS_PORT:-9090}:9090"
    volumes:
      - prometheus_data:/prometheus
      - ./monitoring/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - ./monitoring/prometheus/rules:/etc/prometheus/rules
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=30d'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--web.enable-lifecycle'
      - '--web.enable-admin-api'
    networks:
      - monitoring

  # ============================================
  # Grafana - ì‹œê°í™” ë° ëŒ€ì‹œë³´ë“œ
  # ============================================
  grafana:
    image: grafana/grafana:10.0.0
    container_name: orakgaraki-grafana
    restart: unless-stopped
    ports:
      - "${GRAFANA_PORT:-3000}:3000"
    environment:
      GF_SECURITY_ADMIN_USER: ${GRAFANA_ADMIN_USER:-admin}
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_ADMIN_PASSWORD:-admin123}
      GF_USERS_ALLOW_SIGN_UP: false
      GF_INSTALL_PLUGINS: grafana-piechart-panel,grafana-clock-panel,grafana-simple-json-datasource
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards
      - ./monitoring/grafana/datasources:/etc/grafana/provisioning/datasources
    depends_on:
      - prometheus
    networks:
      - monitoring

  # ============================================
  # Node Exporter - ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­
  # ============================================
  node-exporter:
    image: prom/node-exporter:v1.6.0
    container_name: orakgaraki-node-exporter
    restart: unless-stopped
    ports:
      - "9100:9100"
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    command:
      - '--path.procfs=/host/proc'
      - '--path.rootfs=/rootfs'
      - '--path.sysfs=/host/sys'
      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'
    networks:
      - monitoring

  # ============================================
  # cAdvisor - ì»¨í…Œì´ë„ˆ ë©”íŠ¸ë¦­
  # ============================================
  cadvisor:
    image: gcr.io/cadvisor/cadvisor:v0.47.0
    container_name: orakgaraki-cadvisor
    restart: unless-stopped
    ports:
      - "8080:8080"
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:ro
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
      - /dev/disk/:/dev/disk:ro
    privileged: true
    devices:
      - /dev/kmsg
    networks:
      - monitoring

  # ============================================
  # MySQL Exporter - MySQL ë©”íŠ¸ë¦­
  # ============================================
  mysql-exporter:
    image: prom/mysqld-exporter:v0.15.0
    container_name: orakgaraki-mysql-exporter
    restart: unless-stopped
    ports:
      - "9104:9104"
    environment:
      DATA_SOURCE_NAME: "${DB_USERNAME_LOCAL}:${DB_PASSWORD_LOCAL}@tcp(mysql:3306)/"
    depends_on:
      - mysql
    networks:
      - monitoring

  # ============================================
  # Redis Exporter - Redis ë©”íŠ¸ë¦­
  # ============================================
  redis-exporter:
    image: oliver006/redis_exporter:v1.52.0
    container_name: orakgaraki-redis-exporter
    restart: unless-stopped
    ports:
      - "9121:9121"
    environment:
      REDIS_ADDR: "redis://redis:6379"
      REDIS_PASSWORD: "${REDIS_PASSWORD}"
    depends_on:
      - redis
    networks:
      - monitoring

  # ============================================
  # Kafka Exporter - Kafka ë©”íŠ¸ë¦­
  # ============================================
  kafka-exporter:
    image: danielqsj/kafka-exporter:v1.6.0
    container_name: orakgaraki-kafka-exporter
    restart: unless-stopped
    ports:
      - "9308:9308"
    command:
      - '--kafka.server=kafka:29092'
      - '--web.listen-address=:9308'
    depends_on:
      - kafka
    networks:
      - monitoring

volumes:
  prometheus_data:
  grafana_data:

networks:
  monitoring:
    driver: bridge
```

---

## âš™ï¸ **2ë‹¨ê³„: Prometheus ì„¤ì •**

### monitoring/prometheus/prometheus.yml

```yaml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

rule_files:
  - "rules/*.yml"

scrape_configs:
  # Spring Boot ì• í”Œë¦¬ì¼€ì´ì…˜
  - job_name: 'orakgaraki-app'
    static_configs:
      - targets: ['host.docker.internal:8080']
    metrics_path: '/api/actuator/prometheus'
    scrape_interval: 10s

  # ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­
  - job_name: 'node-exporter'
    static_configs:
      - targets: ['node-exporter:9100']

  # ì»¨í…Œì´ë„ˆ ë©”íŠ¸ë¦­
  - job_name: 'cadvisor'
    static_configs:
      - targets: ['cadvisor:8080']

  # MySQL ë©”íŠ¸ë¦­
  - job_name: 'mysql'
    static_configs:
      - targets: ['mysql-exporter:9104']

  # Redis ë©”íŠ¸ë¦­
  - job_name: 'redis'
    static_configs:
      - targets: ['redis-exporter:9121']

  # Kafka ë©”íŠ¸ë¦­
  - job_name: 'kafka'
    static_configs:
      - targets: ['kafka-exporter:9308']

  # Prometheus ìì²´ ëª¨ë‹ˆí„°ë§
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']

  # Grafana ëª¨ë‹ˆí„°ë§
  - job_name: 'grafana'
    static_configs:
      - targets: ['grafana:3000']
```

### monitoring/prometheus/rules/upload_alerts.yml

```yaml
groups:
  - name: upload_system_alerts
    rules:
      # ì—…ë¡œë“œ ì‹¤íŒ¨ìœ¨ ë†’ìŒ
      - alert: HighUploadFailureRate
        expr: rate(upload_failed_total[5m]) / rate(upload_total[5m]) > 0.1
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "Upload failure rate is above 10%"
          description: "Upload failure rate is {{ $value | humanizePercentage }} for the last 5 minutes"

      # ì²˜ë¦¬ í ì ì²´
      - alert: ProcessingQueueBacklog
        expr: kafka_consumer_lag_sum > 1000
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "Processing queue has significant backlog"
          description: "Kafka consumer lag is {{ $value }} messages"

      # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ë¶€ì¡±
      - alert: LowDatabaseConnections
        expr: mysql_global_status_threads_connected / mysql_global_variables_max_connections > 0.8
        for: 3m
        labels:
          severity: warning
        annotations:
          summary: "MySQL connection pool nearly exhausted"
          description: "{{ $value | humanizePercentage }} of MySQL connections are in use"

      # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë†’ìŒ
      - alert: HighMemoryUsage
        expr: (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) > 0.9
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "High memory usage detected"
          description: "Memory usage is above 90%: {{ $value | humanizePercentage }}"

      # API ì‘ë‹µ ì‹œê°„ ëŠë¦¼
      - alert: SlowAPIResponse
        expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 2
        for: 3m
        labels:
          severity: warning
        annotations:
          summary: "API response time is slow"
          description: "95th percentile response time is {{ $value }}s"
```

---

## ğŸ”§ **3ë‹¨ê³„: Spring Boot Micrometer ì—°ë™**

### build.gradle.ktsì— ì˜ì¡´ì„± ì¶”ê°€

```kotlin
dependencies {
    // ê¸°ì¡´ ì˜ì¡´ì„±ë“¤...

    // Micrometer Prometheus ì—°ë™
    implementation("io.micrometer:micrometer-registry-prometheus")
    implementation("org.springframework.boot:spring-boot-starter-actuator")

    // ì»¤ìŠ¤í…€ ë©”íŠ¸ë¦­ìš©
    implementation("io.micrometer:micrometer-core")
}
```

### application.propertiesì— ì„¤ì • ì¶”ê°€

```properties
# ===============================================
# Actuator & Prometheus ì„¤ì •
# ===============================================
management.endpoints.web.exposure.include=health,info,prometheus,metrics
management.endpoint.prometheus.enabled=true
management.endpoint.metrics.enabled=true
management.endpoint.health.show-details=always
management.metrics.export.prometheus.enabled=true

# ì»¤ìŠ¤í…€ ë©”íŠ¸ë¦­ íƒœê·¸
management.metrics.tags.application=orakgaraki
management.metrics.tags.environment=${SPRING_PROFILES_ACTIVE:local}

# JVM ë©”íŠ¸ë¦­ í™œì„±í™”
management.metrics.enable.jvm=true
management.metrics.enable.system=true
management.metrics.enable.tomcat=true
management.metrics.enable.hikaricp=true
```

### ì»¤ìŠ¤í…€ ë©”íŠ¸ë¦­ êµ¬í˜„

```java
// monitoring/UploadMetrics.java
@Component
@RequiredArgsConstructor
@Slf4j
public class UploadMetrics {

    private final MeterRegistry meterRegistry;

    // ì¹´ìš´í„° ë©”íŠ¸ë¦­
    private final Counter uploadStarted;
    private final Counter uploadCompleted;
    private final Counter uploadFailed;
    private final Counter processingStarted;
    private final Counter processingCompleted;

    // íƒ€ì´ë¨¸ ë©”íŠ¸ë¦­
    private final Timer uploadTimer;
    private final Timer processingTimer;

    // ê²Œì´ì§€ ë©”íŠ¸ë¦­
    private final AtomicLong activeUploads = new AtomicLong(0);
    private final AtomicLong queueSize = new AtomicLong(0);

    @PostConstruct
    public void initMetrics() {
        uploadStarted = Counter.builder("upload.started.total")
            .description("Total number of uploads started")
            .register(meterRegistry);

        uploadCompleted = Counter.builder("upload.completed.total")
            .description("Total number of uploads completed")
            .register(meterRegistry);

        uploadFailed = Counter.builder("upload.failed.total")
            .description("Total number of uploads failed")
            .register(meterRegistry);

        processingStarted = Counter.builder("processing.started.total")
            .description("Total number of processing jobs started")
            .register(meterRegistry);

        processingCompleted = Counter.builder("processing.completed.total")
            .description("Total number of processing jobs completed")
            .register(meterRegistry);

        uploadTimer = Timer.builder("upload.duration")
            .description("Upload duration from start to S3 completion")
            .register(meterRegistry);

        processingTimer = Timer.builder("processing.duration")
            .description("Processing duration from upload to completion")
            .register(meterRegistry);

        // ê²Œì´ì§€ ë“±ë¡
        Gauge.builder("upload.active.count")
            .description("Number of currently active uploads")
            .register(meterRegistry, activeUploads, AtomicLong::get);

        Gauge.builder("processing.queue.size")
            .description("Current processing queue size")
            .register(meterRegistry, queueSize, AtomicLong::get);
    }

    // ì´ë²¤íŠ¸ ë¦¬ìŠ¤ë„ˆë“¤
    @EventListener
    public void onUploadStarted(UploadStartedEvent event) {
        uploadStarted.increment(
            Tags.of(
                "file.type", event.getFileType(),
                "file.size.category", categorizeFileSize(event.getFileSize())
            )
        );
        activeUploads.incrementAndGet();
    }

    @EventListener
    public void onUploadCompleted(UploadCompletedEvent event) {
        uploadCompleted.increment(
            Tags.of(
                "file.type", event.getFileType(),
                "processing.required", String.valueOf(event.requiresProcessing())
            )
        );
        activeUploads.decrementAndGet();

        // ì—…ë¡œë“œ ì‹œê°„ ê¸°ë¡
        uploadTimer.record(event.getDuration(), TimeUnit.MILLISECONDS);
    }

    @EventListener
    public void onUploadFailed(UploadFailedEvent event) {
        uploadFailed.increment(
            Tags.of(
                "error.type", event.getErrorType(),
                "file.type", event.getFileType()
            )
        );
        activeUploads.decrementAndGet();
    }

    @EventListener
    public void onProcessingStarted(ProcessingStartedEvent event) {
        processingStarted.increment(
            Tags.of("job.type", event.getJobType())
        );
        queueSize.decrementAndGet();
    }

    @EventListener
    public void onProcessingCompleted(ProcessingCompletedEvent event) {
        processingCompleted.increment(
            Tags.of(
                "job.type", event.getJobType(),
                "status", event.getStatus().toString()
            )
        );

        // ì²˜ë¦¬ ì‹œê°„ ê¸°ë¡
        processingTimer.record(event.getDuration(), TimeUnit.MILLISECONDS);
    }

    @EventListener
    public void onKafkaMessage(KafkaMessageReceivedEvent event) {
        queueSize.incrementAndGet();
    }

    private String categorizeFileSize(long sizeBytes) {
        if (sizeBytes < 1_000_000) return "small";      // < 1MB
        if (sizeBytes < 10_000_000) return "medium";    // < 10MB
        if (sizeBytes < 100_000_000) return "large";    // < 100MB
        return "xlarge";
    }
}

// monitoring/SystemMetrics.java
@Component
@RequiredArgsConstructor
public class SystemMetrics {

    private final DataSource dataSource;
    private final KafkaTemplate<String, String> kafkaTemplate;

    @Scheduled(fixedDelay = 30000) // 30ì´ˆë§ˆë‹¤
    public void recordDatabaseMetrics() {
        try (var connection = dataSource.getConnection()) {
            var stmt = connection.prepareStatement(
                "SELECT " +
                "  (SELECT COUNT(*) FROM uploads WHERE processing_status = 'PENDING') as pending_uploads," +
                "  (SELECT COUNT(*) FROM uploads WHERE processing_status = 'PROCESSING') as processing_uploads," +
                "  (SELECT COUNT(*) FROM uploads WHERE created_at > NOW() - INTERVAL 1 HOUR) as uploads_last_hour"
            );

            var rs = stmt.executeQuery();
            if (rs.next()) {
                Gauge.builder("database.uploads.pending")
                    .register(Metrics.globalRegistry, rs.getLong("pending_uploads"));

                Gauge.builder("database.uploads.processing")
                    .register(Metrics.globalRegistry, rs.getLong("processing_uploads"));

                Gauge.builder("database.uploads.last_hour")
                    .register(Metrics.globalRegistry, rs.getLong("uploads_last_hour"));
            }
        } catch (SQLException e) {
            log.error("Failed to collect database metrics", e);
        }
    }
}
```

---

## ğŸ¨ **4ë‹¨ê³„: Grafana ëŒ€ì‹œë³´ë“œ ì„¤ì •**

### monitoring/grafana/datasources/prometheus.yml

```yaml
apiVersion: 1
datasources:
  - name: Prometheus
    type: prometheus
    access: proxy
    url: http://prometheus:9090
    isDefault: true
    editable: true
```

### monitoring/grafana/dashboards/dashboard.yml

```yaml
apiVersion: 1
providers:
  - name: 'default'
    orgId: 1
    folder: ''
    type: file
    disableDeletion: false
    updateIntervalSeconds: 10
    allowUiUpdates: true
    options:
      path: /etc/grafana/provisioning/dashboards
```

---

## ğŸš€ **5ë‹¨ê³„: ì‹¤í–‰ ë° ì ‘ì†**

### ëª¨ë‹ˆí„°ë§ ìŠ¤íƒ ì‹œì‘

```bash
# ê¸°ì¡´ ì„œë¹„ìŠ¤ + ëª¨ë‹ˆí„°ë§ ìŠ¤íƒ í•¨ê»˜ ì‹¤í–‰
docker-compose -f docker-compose.yml -f docker-compose.monitoring.yml up -d

# ë˜ëŠ” ë³„ë„ ì‹¤í–‰
docker-compose -f docker-compose.monitoring.yml up -d
```

### ì ‘ì† ì •ë³´

```bash
# Grafana ëŒ€ì‹œë³´ë“œ
http://localhost:3000
- Username: admin
- Password: admin123

# Prometheus ì¿¼ë¦¬ ì¸í„°í˜ì´ìŠ¤
http://localhost:9090

# ê°ì¢… Exporterë“¤
http://localhost:9100  # Node Exporter
http://localhost:8080  # cAdvisor
http://localhost:9104  # MySQL Exporter
http://localhost:9121  # Redis Exporter
http://localhost:9308  # Kafka Exporter
```

---

## ğŸ“Š **6ë‹¨ê³„: ì£¼ìš” ëŒ€ì‹œë³´ë“œ ìƒì„±**

### ì—…ë¡œë“œ ì‹œìŠ¤í…œ ëŒ€ì‹œë³´ë“œ ì¿¼ë¦¬ë“¤

```promql
# ì´ˆë‹¹ ì—…ë¡œë“œ ìˆ˜
rate(upload_started_total[5m])

# ì—…ë¡œë“œ ì„±ê³µë¥ 
rate(upload_completed_total[5m]) / rate(upload_started_total[5m]) * 100

# í‰ê·  ì—…ë¡œë“œ ì‹œê°„
rate(upload_duration_sum[5m]) / rate(upload_duration_count[5m])

# í˜„ì¬ í™œì„± ì—…ë¡œë“œ ìˆ˜
upload_active_count

# ì²˜ë¦¬ í í¬ê¸°
processing_queue_size

# API ì‘ë‹µ ì‹œê°„ (95th percentile)
histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))

# ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ 
(1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100

# CPU ì‚¬ìš©ë¥ 
100 - (avg by (instance) (rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100)

# MySQL ì—°ê²° ìˆ˜
mysql_global_status_threads_connected

# Kafka Consumer Lag
kafka_consumer_lag_sum

# Redis ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
redis_memory_used_bytes
```

---

## ğŸ”” **7ë‹¨ê³„: ì•ŒëŒ ì„¤ì •**

### Grafana ì•ŒëŒ ê·œì¹™ ì˜ˆì œ

```json
{
  "alert": {
    "name": "High Upload Failure Rate",
    "frequency": "1m",
    "conditions": [
      {
        "query": {
          "queryType": "",
          "refId": "A",
          "model": {
            "expr": "rate(upload_failed_total[5m]) / rate(upload_started_total[5m]) > 0.1",
            "interval": "",
            "legendFormat": "",
            "refId": "A"
          }
        },
        "reducer": {
          "type": "last",
          "params": []
        },
        "evaluator": {
          "params": [0],
          "type": "gt"
        }
      }
    ],
    "notifications": [
      {
        "uid": "slack-notifications"
      }
    ]
  }
}
```

---

## ğŸ’¡ **ì„±ëŠ¥ ìµœì í™” íŒ**

### Prometheus ë°ì´í„° ë³´ì¡´ ì •ì±…

```yaml
# prometheus.yml
global:
  scrape_interval: 15s     # ìš´ì˜í™˜ê²½ì—ì„œëŠ” 30s ê¶Œì¥
  evaluation_interval: 15s

# ë³´ì¡´ ê¸°ê°„ ì„¤ì • (ì»¨í…Œì´ë„ˆ commandì—ì„œ)
--storage.tsdb.retention.time=30d  # 30ì¼ ë³´ì¡´
--storage.tsdb.retention.size=10GB # ìµœëŒ€ 10GB
```

### ë©”íŠ¸ë¦­ ìƒ˜í”Œë§ ìµœì í™”

```java
// ê³ ë¹ˆë„ ë©”íŠ¸ë¦­ì€ ìƒ˜í”Œë§ ì ìš©
@Component
public class SampledMetrics {

    private final Random random = new Random();

    public void recordIfSampled(String metricName, double value) {
        // 10% ìƒ˜í”Œë§
        if (random.nextDouble() < 0.1) {
            Metrics.counter(metricName).increment(value);
        }
    }
}
```

---

## ğŸ›¡ï¸ **ë³´ì•ˆ ì„¤ì •**

### Grafana ë³´ì•ˆ ê°•í™”

```yaml
# docker-compose.monitoring.yml
grafana:
  environment:
    # ê¸°ë³¸ ì„¤ì •ë“¤...
    GF_SECURITY_SECRET_KEY: "your-secret-key-here"
    GF_SECURITY_DISABLE_GRAVATAR: true
    GF_ANALYTICS_REPORTING_ENABLED: false
    GF_ANALYTICS_CHECK_FOR_UPDATES: false
    GF_USERS_DEFAULT_THEME: dark
    GF_AUTH_ANONYMOUS_ENABLED: false
```

### Prometheus ì ‘ê·¼ ì œí•œ

```yaml
# nginx.conf (ë¦¬ë²„ìŠ¤ í”„ë¡ì‹œ)
server {
    location /prometheus/ {
        auth_basic "Prometheus";
        auth_basic_user_file /etc/nginx/.htpasswd;
        proxy_pass http://prometheus:9090/;
    }
}
```

---

## ğŸ“ˆ **CloudWatch vs Grafana+Prometheus ë¹„êµ**

| ê¸°ëŠ¥ | CloudWatch | Grafana+Prometheus |
|------|------------|-------------------|
| **ë¹„ìš©** | ë†’ìŒ ($100+/ì›”) | ë¬´ë£Œ |
| **ì»¤ìŠ¤í„°ë§ˆì´ì§•** | ì œí•œì  | ë¬´ì œí•œ |
| **ì‹œê°í™”** | ê¸°ë³¸ì  | ë§¤ìš° ì•„ë¦„ë‹¤ì›€ |
| **ì•ŒëŒ** | ìœ ë£Œ | ë¬´ë£Œ ë¬´ì œí•œ |
| **ë°ì´í„° ë³´ì¡´** | ìœ ë£Œ | ììœ ë¡­ê²Œ ì„¤ì • |
| **ì¿¼ë¦¬ ì–¸ì–´** | ì œí•œì  | PromQL (ê°•ë ¥í•¨) |
| **í†µí•©ì„±** | AWSë§Œ | ëª¨ë“  ì‹œìŠ¤í…œ |
| **í•™ìŠµ ê³¡ì„ ** | ì‰¬ì›€ | ë³´í†µ |

**ê²°ë¡ : Grafana+Prometheusê°€ ì••ë„ì ìœ¼ë¡œ ìœ ë¦¬í•©ë‹ˆë‹¤!** ğŸ¯

<function_calls>
<invoke name="TodoWrite">
<parameter name="todos">[{"content": "Grafana + Prometheus \uc124\uc815 \uac00\uc774\ub4dc \uc791\uc131", "status": "completed", "activeForm": "Grafana + Prometheus \uc124\uc815 \uac00\uc774\ub4dc \uc791\uc131 \uc911"}, {"content": "Docker Compose\uc5d0 \ubaa8\ub2c8\ud130\ub9c1 \uc2a4\ud0dd \ucd94\uac00", "status": "in_progress", "activeForm": "Docker Compose\uc5d0 \ubaa8\ub2c8\ud130\ub9c1 \uc2a4\ud0dd \ucd94\uac00 \uc911"}, {"content": "Spring Boot Micrometer \uc5f0\ub3d9 \uc124\uc815", "status": "pending", "activeForm": "Spring Boot Micrometer \uc5f0\ub3d9 \uc124\uc815 \uc911"}, {"content": "Grafana \ub300\uc2dc\ubcf4\ub4dc \uc608\uc81c \uc791\uc131", "status": "pending", "activeForm": "Grafana \ub300\uc2dc\ubcf4\ub4dc \uc608\uc81c \uc791\uc131 \uc911"}]