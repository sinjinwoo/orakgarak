/**
 * ì‹¤ì‹œê°„ í”¼ì¹˜ ê·¸ë˜í”„ ì»´í¬ë„ŒíŠ¸
 * - Web Audio APIë¥¼ í™œìš©í•œ ì‹¤ì‹œê°„ í”¼ì¹˜ ê°ì§€
 * - í”¼ì¹˜ ë°ì´í„°ë¥¼ line chartë¡œ ì‹œê°í™”
 * - ë…¹ìŒ ìƒíƒœì— ë”°ë¼ ìë™ìœ¼ë¡œ í™œì„±í™”/ë¹„í™œì„±í™”
 */

import React, { useState, useEffect, useRef, useCallback, useMemo } from 'react';
import { Box, Typography, Paper } from '@mui/material';

interface PitchGraphProps {
  isRecording: boolean;
}

interface PitchData {
  frequency: number;
  timestamp: number;
  note: string;
  octave: number;
  cents: number;
}

const PitchGraph: React.FC<PitchGraphProps> = ({ isRecording }) => {
  // ìƒíƒœ ê´€ë¦¬
  const [pitchData, setPitchData] = useState<PitchData[]>([]);
  const [currentPitch, setCurrentPitch] = useState<PitchData | null>(null);
  const [isActive, setIsActive] = useState(false);
  const [debugInfo, setDebugInfo] = useState({
    micLevel: 0,
    dataPoints: 0,
    lastUpdate: '',
    isDetecting: false,
    error: ''
  });
  
  // refs
  const canvasRef = useRef<HTMLCanvasElement>(null);
  const animationRef = useRef<number | undefined>(undefined);
  const audioContextRef = useRef<AudioContext | null>(null);
  const analyserRef = useRef<AnalyserNode | null>(null);
  const microphoneRef = useRef<MediaStreamAudioSourceNode | null>(null);
  const dataArrayRef = useRef<Float32Array | null>(null);

  // ìŒê³„ ì •ë³´
  const noteNames = useMemo(() => ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B'], []);
  
  // ì£¼íŒŒìˆ˜ë¥¼ ìŒê³„ë¡œ ë³€í™˜
  const frequencyToNote = useCallback((frequency: number): { note: string; octave: number; cents: number } => {
    if (frequency <= 0) return { note: '', octave: 0, cents: 0 };
    
    // A4 = 440Hzë¥¼ ê¸°ì¤€ìœ¼ë¡œ ê³„ì‚°
    const A4 = 440;
    const semitone = 12 * Math.log2(frequency / A4);
    const noteNumber = Math.round(semitone) + 69; // MIDI note number
    const octave = Math.floor(noteNumber / 12) - 1;
    const noteIndex = noteNumber % 12;
    const note = noteNames[noteIndex < 0 ? noteIndex + 12 : noteIndex];
    
    // ì„¼íŠ¸ ê³„ì‚°
    const cents = (semitone - Math.round(semitone)) * 100;
    
    return { note, octave, cents: Math.round(cents) };
  }, [noteNames]);

  // ê°„ë‹¨í•˜ê³  íš¨ê³¼ì ì¸ í”¼ì¹˜ ê°ì§€ ì•Œê³ ë¦¬ì¦˜ (ì£¼íŒŒìˆ˜ ë„ë©”ì¸ ë¶„ì„)
  const detectFundamentalFrequency = useCallback((buffer: Float32Array, sampleRate: number): number => {
    // 1. ì‹ í˜¸ ì—ë„ˆì§€ ê³„ì‚° (ë…¸ì´ì¦ˆ í•„í„°ë§)
    let energy = 0;
    for (let i = 0; i < buffer.length; i++) {
      energy += Math.abs(buffer[i]);
    }
    energy = energy / buffer.length;
    
    // 2. ìµœì†Œ ì—ë„ˆì§€ ì„ê³„ê°’ (ë„ˆë¬´ ì‘ì€ ì†Œë¦¬ëŠ” ë¬´ì‹œ)
    if (energy < 0.01) {
      return 0;
    }
    
    // 3. ì£¼íŒŒìˆ˜ ë„ë©”ì¸ì—ì„œ ìµœëŒ€ í”¼í¬ ì°¾ê¸°
    let maxMagnitude = -Infinity;
    let maxIndex = 0;
    
    for (let i = 0; i < buffer.length; i++) {
      if (buffer[i] > maxMagnitude) {
        maxMagnitude = buffer[i];
        maxIndex = i;
      }
    }
    
    // 4. ì£¼íŒŒìˆ˜ ê³„ì‚°
    const frequency = (maxIndex / buffer.length) * (sampleRate / 2);
    
    // 5. ìŒì„± ì£¼íŒŒìˆ˜ ë²”ìœ„ í™•ì¸ (80Hz ~ 800Hz)
    if (frequency < 80 || frequency > 800) {
      return 0;
    }
    
    // 6. ì‹ í˜¸ ê°•ë„ í™•ì¸ (dB ìŠ¤ì¼€ì¼ì—ì„œ -50dB ì´ìƒ)
    if (maxMagnitude < -50) {
      return 0;
    }
    
    console.log('ğŸµ í”¼ì¹˜ ê°ì§€:', {
      frequency: Math.round(frequency),
      magnitude: maxMagnitude.toFixed(2),
      energy: energy.toFixed(4),
      index: maxIndex
    });
    
    return frequency;
  }, []);

  // í”¼ì¹˜ ë¶„ì„ í•¨ìˆ˜ (ê°„ë‹¨í•˜ê³  ì•ˆì •ì )
  const analyzePitch = useCallback(() => {
    if (!analyserRef.current || !dataArrayRef.current) return;

    // ì£¼íŒŒìˆ˜ ë„ë©”ì¸ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    analyserRef.current.getFloatFrequencyData(dataArrayRef.current);
    
    // ë§ˆì´í¬ ì…ë ¥ ë ˆë²¨ ê³„ì‚° (ë³¼ë¥¨ í‘œì‹œìš©)
    let sum = 0;
    for (let i = 0; i < dataArrayRef.current.length; i++) {
      sum += Math.abs(dataArrayRef.current[i]);
    }
    const micLevel = (sum / dataArrayRef.current.length) * 100;
    
    // í”¼ì¹˜ ê°ì§€
    const frequency = detectFundamentalFrequency(dataArrayRef.current, audioContextRef.current?.sampleRate || 44100);
    
    // ë””ë²„ê·¸ ì •ë³´ ì—…ë°ì´íŠ¸
    setDebugInfo(prev => ({
      ...prev,
      micLevel: Math.round(micLevel),
      dataPoints: pitchData.length,
      lastUpdate: new Date().toLocaleTimeString(),
      isDetecting: frequency > 0,
      error: ''
    }));
    
    // í”¼ì¹˜ê°€ ê°ì§€ë˜ë©´ ë°ì´í„° ì¶”ê°€
    if (frequency > 0) {
      const noteInfo = frequencyToNote(frequency);
      const pitchDataPoint: PitchData = {
        frequency,
        timestamp: Date.now(),
        note: noteInfo.note,
        octave: noteInfo.octave,
        cents: noteInfo.cents,
      };
      
      setCurrentPitch(pitchDataPoint);
      setPitchData(prev => [...prev.slice(-199), pitchDataPoint]); // ìµœê·¼ 200ê°œë§Œ ìœ ì§€
    }
  }, [pitchData.length, frequencyToNote, detectFundamentalFrequency]);

  // ê·¸ë˜í”„ ê·¸ë¦¬ê¸° í•¨ìˆ˜
  const drawGraph = useCallback(() => {
    const canvas = canvasRef.current;
    if (!canvas) return;

    const ctx = canvas.getContext('2d');
    if (!ctx) return;

    const { width, height } = canvas;
    
    // ìº”ë²„ìŠ¤ í´ë¦¬ì–´
    ctx.clearRect(0, 0, width, height);
    
    // ë°°ê²½
    ctx.fillStyle = '#1a1a1a';
    ctx.fillRect(0, 0, width, height);

    // ë§ˆì´í¬ ì…ë ¥ ë ˆë²¨ í‘œì‹œ
    const micLevelBar = (debugInfo.micLevel / 100) * width;
    ctx.fillStyle = debugInfo.micLevel > 5 ? '#4CAF50' : '#666';
    ctx.fillRect(0, height - 5, micLevelBar, 5);

    // í”¼ì¹˜ ë°ì´í„° ì •ê·œí™” (80Hz ~ 800Hz ë²”ìœ„)
    const minFreq = 80;
    const maxFreq = 800;
    
    // ì‹œê°„ ë²”ìœ„ ê³„ì‚° (ìµœê·¼ 15ì´ˆ)
    const now = Date.now();
    const timeRange = 15000; // 15ì´ˆ
    const startTime = now - timeRange;
    
    // ìµœê·¼ 15ì´ˆ ë°ì´í„° í•„í„°ë§ ë° ì •ê·œí™”
    const normalizedData = pitchData
      .filter(p => p.timestamp >= startTime) // ìµœê·¼ 15ì´ˆ ë°ì´í„°ë§Œ
      .map((p) => ({
        x: ((p.timestamp - startTime) / timeRange) * width,
        y: height - ((p.frequency - minFreq) / (maxFreq - minFreq)) * height,
        frequency: p.frequency,
        note: p.note,
        octave: p.octave,
        cents: p.cents
      }))
      .sort((a, b) => a.x - b.x); // X ì¢Œí‘œ ìˆœìœ¼ë¡œ ì •ë ¬

    // ìƒíƒœ í‘œì‹œ
    ctx.fillStyle = '#fff';
    ctx.font = '12px Arial';
    ctx.textAlign = 'left';
    ctx.fillText(`ë§ˆì´í¬: ${debugInfo.micLevel}%`, 5, 15);
    ctx.fillText(`ë°ì´í„°: ${debugInfo.dataPoints}ê°œ`, 5, 30);
    ctx.fillText(`ê°ì§€: ${debugInfo.isDetecting ? 'YES' : 'NO'}`, 5, 45);
    ctx.fillText(`ê·¸ë˜í”„: ${normalizedData.length}ê°œ`, 5, 60);

    if (pitchData.length < 2) {
      // ë°ì´í„°ê°€ ì—†ì„ ë•Œ ì•ˆë‚´ ë©”ì‹œì§€
      ctx.fillStyle = '#666';
      ctx.font = '14px Arial';
      ctx.textAlign = 'center';
      ctx.fillText('í”¼ì¹˜ ë°ì´í„°ë¥¼ ìˆ˜ì§‘ ì¤‘...', width / 2, height / 2);
      ctx.fillText('ë§ˆì´í¬ì— ì†Œë¦¬ë¥¼ ë‚´ë³´ì„¸ìš”', width / 2, height / 2 + 20);
      return;
    }

    // ê·¸ë¦¬ë“œ ê·¸ë¦¬ê¸°
    ctx.strokeStyle = '#333';
    ctx.lineWidth = 1;
    
    // ìˆ˜í‰ì„  (ì£¼íŒŒìˆ˜ ê¸°ì¤€ì„ )
    const midY = height / 2;
    ctx.beginPath();
    ctx.moveTo(0, midY);
    ctx.lineTo(width, midY);
    ctx.stroke();


    // í”¼ì¹˜ ë¼ì¸ ê·¸ë¦¬ê¸°
    if (normalizedData.length > 0) {
      // ë©”ì¸ í”¼ì¹˜ ë¼ì¸
      ctx.strokeStyle = '#4CAF50';
      ctx.lineWidth = 3;
      ctx.beginPath();
      
      // ì²« ë²ˆì§¸ ì ìœ¼ë¡œ ì´ë™
      ctx.moveTo(normalizedData[0].x, normalizedData[0].y);
      
      // ë‚˜ë¨¸ì§€ ì ë“¤ì„ ì—°ê²°
      for (let i = 1; i < normalizedData.length; i++) {
        ctx.lineTo(normalizedData[i].x, normalizedData[i].y);
      }
      
      ctx.stroke();
      
      // ê·¸ë¼ë°ì´ì…˜ ë°°ê²½ (í”¼ì¹˜ ì˜ì—­)
      if (normalizedData.length > 1) {
        const gradient = ctx.createLinearGradient(0, 0, 0, height);
        gradient.addColorStop(0, '#4CAF5020');
        gradient.addColorStop(1, '#4CAF5005');
        
        ctx.fillStyle = gradient;
        ctx.beginPath();
        ctx.moveTo(normalizedData[0].x, height);
        for (let i = 0; i < normalizedData.length; i++) {
          ctx.lineTo(normalizedData[i].x, normalizedData[i].y);
        }
        ctx.lineTo(normalizedData[normalizedData.length - 1].x, height);
        ctx.closePath();
        ctx.fill();
      }
      
      // ìµœê·¼ ë°ì´í„° í¬ì¸íŠ¸ë“¤ì„ ê°•ì¡° í‘œì‹œ
      ctx.fillStyle = '#4CAF50';
      normalizedData.slice(-10).forEach((point, index) => {
        const alpha = (index + 1) / 10; // ìµœê·¼ì¼ìˆ˜ë¡ ë” ë°ê²Œ
        ctx.globalAlpha = alpha;
        ctx.beginPath();
        ctx.arc(point.x, point.y, 3, 0, Math.PI * 2);
        ctx.fill();
      });
      ctx.globalAlpha = 1; // ì•ŒíŒŒê°’ ë¦¬ì…‹
    }

    // í˜„ì¬ í”¼ì¹˜ í‘œì‹œ (ì‹¤ì‹œê°„ ì›€ì§ì„ ê°•ì¡°)
    if (currentPitch) {
      const currentX = width - 20;
      const currentY = height - ((currentPitch.frequency - minFreq) / (maxFreq - minFreq)) * height;
      
      // í˜„ì¬ í”¼ì¹˜ ìˆ˜í‰ì„  (ê¹œë¹¡ì´ëŠ” íš¨ê³¼)
      const time = Date.now();
      const blink = Math.sin(time / 200) > 0; // 200msë§ˆë‹¤ ê¹œë¹¡ì„
      ctx.strokeStyle = blink ? '#FF5722' : '#FF572280';
      ctx.lineWidth = 2;
      ctx.setLineDash([8, 8]);
      ctx.beginPath();
      ctx.moveTo(0, currentY);
      ctx.lineTo(width, currentY);
      ctx.stroke();
      ctx.setLineDash([]);
      
      // í˜„ì¬ í”¼ì¹˜ ì  (í„ìŠ¤ íš¨ê³¼)
      const pulse = 4 + Math.sin(time / 100) * 2; // 100msë§ˆë‹¤ í¬ê¸° ë³€í™”
      ctx.fillStyle = '#FF5722';
      ctx.beginPath();
      ctx.arc(currentX, currentY, pulse, 0, Math.PI * 2);
      ctx.fill();
      
      // ì™¸ë¶€ ë§ (í„ìŠ¤ íš¨ê³¼)
      ctx.strokeStyle = '#FF5722';
      ctx.lineWidth = 2;
      ctx.beginPath();
      ctx.arc(currentX, currentY, pulse + 8, 0, Math.PI * 2);
      ctx.stroke();
      
      // í˜„ì¬ í”¼ì¹˜ ì •ë³´ í…ìŠ¤íŠ¸ (ë°°ê²½ ì¶”ê°€)
      ctx.fillStyle = 'rgba(0, 0, 0, 0.7)';
      ctx.fillRect(currentX - 60, currentY - 25, 55, 35);
      
      ctx.fillStyle = '#fff';
      ctx.font = 'bold 12px Arial';
      ctx.textAlign = 'right';
      ctx.fillText(`${currentPitch.note}${currentPitch.octave}`, currentX - 5, currentY - 8);
      ctx.font = '10px Arial';
      ctx.fillText(`${Math.round(currentPitch.frequency)}Hz`, currentX - 5, currentY + 8);
    }

    // ì£¼íŒŒìˆ˜ ë²”ìœ„ í‘œì‹œ
    ctx.fillStyle = '#666';
    ctx.font = '10px Arial';
    ctx.textAlign = 'left';
    ctx.fillText(`${minFreq}Hz`, 5, height - 5);
    ctx.textAlign = 'right';
    ctx.fillText(`${maxFreq}Hz`, width - 5, 15);
  }, [pitchData, currentPitch, debugInfo.micLevel, debugInfo.dataPoints, debugInfo.isDetecting]);

  // ë§ˆì´í¬ ì‹œì‘ í•¨ìˆ˜
  const startMicrophone = useCallback(async () => {
    try {
      // ì˜¤ë””ì˜¤ ì»¨í…ìŠ¤íŠ¸ ìƒì„±
      const AudioContextClass = window.AudioContext || (window as unknown as { webkitAudioContext: typeof AudioContext }).webkitAudioContext;
      const audioContext = new AudioContextClass() as AudioContext;
      audioContextRef.current = audioContext;
      
      // ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¼ ê°€ì ¸ì˜¤ê¸°
      const stream = await navigator.mediaDevices.getUserMedia({ 
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          sampleRate: 44100
        } 
      });
      
      // ì˜¤ë””ì˜¤ ì†ŒìŠ¤ ìƒì„±
      const microphone = audioContext.createMediaStreamSource(stream);
      microphoneRef.current = microphone;
      
      // ë¶„ì„ê¸° ìƒì„±
      const analyser = audioContext.createAnalyser();
      analyser.fftSize = 2048;
      analyser.smoothingTimeConstant = 0.8;
      analyserRef.current = analyser;
      
      // ë°ì´í„° ë°°ì—´ ìƒì„±
      const bufferLength = analyser.frequencyBinCount;
      dataArrayRef.current = new Float32Array(bufferLength);
      
      // ì—°ê²°
      microphone.connect(analyser);
      
      setIsActive(true);
      setPitchData([]);
      
    } catch (err) {
      console.error('ë§ˆì´í¬ ì ‘ê·¼ ì‹¤íŒ¨:', err);
      setIsActive(false);
      setDebugInfo(prev => ({
        ...prev,
        error: `ë§ˆì´í¬ ì ‘ê·¼ ì‹¤íŒ¨: ${err instanceof Error ? err.message : 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜'}`,
        micLevel: 0
      }));
    }
  }, []);

  // ë¦¬ì†ŒìŠ¤ ì •ë¦¬ í•¨ìˆ˜
  const cleanupResources = useCallback(() => {
    // ì• ë‹ˆë©”ì´ì…˜ ì •ë¦¬
    if (animationRef.current) {
      cancelAnimationFrame(animationRef.current);
      animationRef.current = undefined;
    }
    
    // ë§ˆì´í¬ ì—°ê²° í•´ì œ
    if (microphoneRef.current) {
      try {
        microphoneRef.current.disconnect();
      } catch (error) {
        console.warn('ë§ˆì´í¬ ì—°ê²° í•´ì œ ì¤‘ ì˜¤ë¥˜:', error);
      }
      microphoneRef.current = null;
    }
    
    // ì˜¤ë””ì˜¤ ì»¨í…ìŠ¤íŠ¸ ì •ë¦¬
    if (audioContextRef.current) {
      try {
        if (audioContextRef.current.state !== 'closed') {
          audioContextRef.current.close();
        }
      } catch (error) {
        console.warn('ì˜¤ë””ì˜¤ ì»¨í…ìŠ¤íŠ¸ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜:', error);
      }
      audioContextRef.current = null;
    }
    
    // ë¶„ì„ê¸° ì •ë¦¬
    analyserRef.current = null;
    dataArrayRef.current = null;
    
    setIsActive(false);
    setCurrentPitch(null);
  }, []);

  // ë§ˆì´í¬ ì¤‘ì§€ í•¨ìˆ˜
  const stopMicrophone = useCallback(() => {
    cleanupResources();
  }, [cleanupResources]);

  // ë…¹ìŒ ìƒíƒœì— ë”°ë¼ ë§ˆì´í¬ ì‹œì‘/ì¤‘ì§€
  useEffect(() => {
    if (isRecording) {
      startMicrophone();
    } else {
      stopMicrophone();
    }
    
    // ì»´í¬ë„ŒíŠ¸ ì–¸ë§ˆìš´íŠ¸ ì‹œ ì •ë¦¬
    return () => {
      cleanupResources();
    };
  }, [isRecording, startMicrophone, stopMicrophone, cleanupResources]);

  // í™œì„±í™” ìƒíƒœì— ë”°ë¼ ì• ë‹ˆë©”ì´ì…˜ ì‹œì‘/ì¤‘ì§€
  useEffect(() => {
    if (isActive) {
      const animate = () => {
        drawGraph();
        animationRef.current = requestAnimationFrame(animate);
      };
      animate();
    } else {
      if (animationRef.current) {
        cancelAnimationFrame(animationRef.current);
        animationRef.current = undefined;
      }
    }
  }, [isActive, drawGraph]);

  // í”¼ì¹˜ ë¶„ì„ ì£¼ê¸°ì  ì‹¤í–‰ (ì ì ˆí•œ ì£¼ê¸°ë¡œ ì‹¤ì‹œê°„ì„±ê³¼ ì„±ëŠ¥ ê· í˜•)
  useEffect(() => {
    if (!isActive) return;
    
    const interval = setInterval(analyzePitch, 100); // 100msë§ˆë‹¤ ë¶„ì„ (10fps)
    return () => clearInterval(interval);
  }, [isActive, analyzePitch]);

  return (
    <Box sx={{ height: '100%', display: 'flex', flexDirection: 'column' }}>
      {/* í—¤ë” */}
      <Box sx={{ 
        display: 'flex', 
        alignItems: 'center', 
        justifyContent: 'space-between',
        mb: 3
      }}>
        <Box sx={{ display: 'flex', alignItems: 'center', gap: 2 }}>
          <Box sx={{
            width: 40,
            height: 40,
            borderRadius: '10px',
            background: 'linear-gradient(45deg, #00ffff, #ff0080)',
            display: 'flex',
            alignItems: 'center',
            justifyContent: 'center',
            boxShadow: '0 0 15px rgba(0, 255, 255, 0.3)'
          }}>
            <Typography sx={{ color: '#000', fontSize: 20, fontWeight: 'bold' }}>ğŸµ</Typography>
          </Box>
          <Box>
            <Typography 
              variant="h6" 
              sx={{ 
                color: '#00ffff',
                fontWeight: 700,
                letterSpacing: '0.05em',
                textShadow: '0 0 10px rgba(0, 255, 255, 0.5)'
              }}
            >
              NEURAL PITCH
            </Typography>
            <Typography 
              variant="caption" 
              sx={{ 
                color: '#888',
                textTransform: 'uppercase',
                letterSpacing: '0.1em'
              }}
            >
              FREQUENCY ANALYZER
            </Typography>
          </Box>
        </Box>

        <Box sx={{ display: 'flex', alignItems: 'center', gap: 1 }}>
          <Box sx={{
            width: 8,
            height: 8,
            borderRadius: '50%',
            background: isActive ? '#00ff00' : '#888',
            boxShadow: isActive ? '0 0 10px #00ff00' : 'none',
            animation: isActive ? 'pulse 1s infinite' : 'none',
            '@keyframes pulse': {
              '0%': { opacity: 1 },
              '50%': { opacity: 0.5 },
              '100%': { opacity: 1 }
            }
          }} />
          <Typography 
            variant="caption" 
            sx={{ 
              color: isActive ? '#00ff00' : '#888',
              fontWeight: 600,
              textTransform: 'uppercase',
              fontFamily: 'monospace'
            }}
          >
            {isActive ? 'ACTIVE' : 'STANDBY'}
          </Typography>
        </Box>
      </Box>
      
      {/* ë””ë²„ê·¸ ì •ë³´ í‘œì‹œ */}
      <Paper elevation={1} sx={{ p: 1, mb: 2, backgroundColor: '#f5f5f5' }}>
        <Box sx={{ display: 'flex', justifyContent: 'space-between', flexWrap: 'wrap', gap: 1 }}>
          <Typography variant="caption" color={debugInfo.micLevel > 5 ? 'success.main' : 'text.secondary'}>
            ë§ˆì´í¬: {debugInfo.micLevel}%
          </Typography>
          <Typography variant="caption" color="text.secondary">
            ë°ì´í„°: {debugInfo.dataPoints}ê°œ
          </Typography>
          <Typography variant="caption" color={debugInfo.isDetecting ? 'success.main' : 'text.secondary'}>
            ê°ì§€: {debugInfo.isDetecting ? 'YES' : 'NO'}
          </Typography>
          <Typography variant="caption" color="text.secondary">
            ì—…ë°ì´íŠ¸: {debugInfo.lastUpdate}
          </Typography>
        </Box>
        {debugInfo.error && (
          <Typography variant="caption" color="error" sx={{ display: 'block', mt: 1 }}>
            {debugInfo.error}
          </Typography>
        )}
      </Paper>
      
      {/* í˜„ì¬ í”¼ì¹˜ ì •ë³´ í‘œì‹œ */}
      {currentPitch && (
        <Paper elevation={2} sx={{ p: 2, mb: 2, textAlign: 'center' }}>
          <Typography variant="h5" sx={{ 
            fontWeight: 'bold', 
            color: '#4CAF50',
            textShadow: `0 0 10px #4CAF5040`
          }}>
            {currentPitch.note}{currentPitch.octave}
          </Typography>
          <Typography variant="body2" color="text.secondary">
            {Math.round(currentPitch.frequency)}Hz
            {currentPitch.cents !== 0 && ` (${currentPitch.cents > 0 ? '+' : ''}${currentPitch.cents}Â¢)`}
          </Typography>
          <Typography variant="body2" color="text.secondary">
            {isRecording ? 'ë…¹ìŒ ì¤‘...' : 'ëŒ€ê¸° ì¤‘...'}
          </Typography>
        </Paper>
      )}

      {/* í”¼ì¹˜ ê·¸ë˜í”„ ìº”ë²„ìŠ¤ */}
      <Paper elevation={3} sx={{ overflow: 'hidden', borderRadius: 2 }}>
        <canvas
          ref={canvasRef}
          width={300}
          height={200}
          style={{
            width: '100%',
            height: '200px',
            display: 'block'
          }}
        />
      </Paper>
    </Box>
  );
};

export default PitchGraph;
