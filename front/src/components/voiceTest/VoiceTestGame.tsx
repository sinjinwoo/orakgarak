import React, { useState, useEffect, useRef, useCallback } from 'react';
import {
  Box,
  Typography,
  Button,
  Paper,
  LinearProgress,
  CircularProgress,
  Alert,
  IconButton,
  Card,
  CardContent
} from '@mui/material';
import {
  Mic,
  MicOff,
  PlayArrow,
  Pause,
  VolumeUp,
  MusicNote,
  CheckCircle,
  Cancel
} from '@mui/icons-material';
import type { VoiceTestStep, VoiceTestResult, VoiceTestSession } from '../../types/voiceAnalysis';

interface VoiceTestGameProps {
  onTestComplete: (results: VoiceTestResult[]) => void;
  onTestCancel: () => void;
}

// í…ŒìŠ¤íŠ¸ ë‹¨ê³„ ì •ì˜
const testSteps: VoiceTestStep[] = [
  {
    id: 'warmup',
    title: 'ğŸ¤ ì›Œë°ì—…',
    description: 'ë§ˆì´í¬ë¥¼ ì¼œê³  ê°„ë‹¨í•œ ì†Œë¦¬ë¥¼ ë‚´ë³´ì„¸ìš”',
    instruction: 'ë§ˆì´í¬ ë²„íŠ¼ì„ ëˆ„ë¥´ê³  "ì•„" ì†Œë¦¬ë¥¼ 3ì´ˆê°„ ë‚´ë³´ì„¸ìš”',
    duration: 3,
    type: 'range'
  },
  {
    id: 'low_note',
    title: 'ğŸµ ë‚®ì€ ìŒ',
    description: 'ê°€ì¥ ë‚®ì€ ìŒì„ ë‚´ë³´ì„¸ìš”',
    instruction: 'ë§ˆì´í¬ ë²„íŠ¼ì„ ëˆ„ë¥´ê³  ê°€ëŠ¥í•œ í•œ ë‚®ì€ ìŒìœ¼ë¡œ "ì•„" ì†Œë¦¬ë¥¼ 4ì´ˆê°„ ë‚´ë³´ì„¸ìš”',
    duration: 4,
    type: 'range'
  },
  {
    id: 'high_note',
    title: 'ğŸ¶ ë†’ì€ ìŒ',
    description: 'ê°€ì¥ ë†’ì€ ìŒì„ ë‚´ë³´ì„¸ìš”',
    instruction: 'ë§ˆì´í¬ ë²„íŠ¼ì„ ëˆ„ë¥´ê³  ê°€ëŠ¥í•œ í•œ ë†’ì€ ìŒìœ¼ë¡œ "ì•„" ì†Œë¦¬ë¥¼ 4ì´ˆê°„ ë‚´ë³´ì„¸ìš”',
    duration: 4,
    type: 'range'
  },
  {
    id: 'sustain',
    title: 'ğŸ¼ ìŒ ìœ ì§€',
    description: 'ì•ˆì •ì ìœ¼ë¡œ ìŒì„ ìœ ì§€í•´ë³´ì„¸ìš”',
    instruction: 'ë§ˆì´í¬ ë²„íŠ¼ì„ ëˆ„ë¥´ê³  í¸ì•ˆí•œ ìŒìœ¼ë¡œ "ì•„" ì†Œë¦¬ë¥¼ 5ì´ˆê°„ ì¼ì •í•˜ê²Œ ìœ ì§€í•´ë³´ì„¸ìš”',
    duration: 5,
    type: 'sustain'
  },
  {
    id: 'melody',
    title: 'ğŸ¹ ë©œë¡œë””',
    description: 'ê°„ë‹¨í•œ ë©œë¡œë””ë¥¼ ë”°ë¼í•´ë³´ì„¸ìš”',
    instruction: 'ë§ˆì´í¬ ë²„íŠ¼ì„ ëˆ„ë¥´ê³  "ë„ë ˆë¯¸íŒŒì†”"ì„ ë”°ë¼ ë¶ˆëŸ¬ë³´ì„¸ìš”',
    duration: 6,
    type: 'melody'
  }
];

const VoiceTestGame: React.FC<VoiceTestGameProps> = ({ onTestComplete, onTestCancel }) => {
  const [session, setSession] = useState<VoiceTestSession>({
    id: `session_${Date.now()}`,
    startTime: Date.now(),
    currentStep: 0,
    results: [],
    isCompleted: false,
    overallScore: 0
  });

  const [isRecording, setIsRecording] = useState(false);
  const [isAnalyzing, setIsAnalyzing] = useState(false);
  const [currentTime, setCurrentTime] = useState(0);
  const [volume, setVolume] = useState(0);
  const [error, setError] = useState<string | null>(null);

  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const audioContextRef = useRef<AudioContext | null>(null);
  const analyserRef = useRef<AnalyserNode | null>(null);
  const microphoneRef = useRef<MediaStreamAudioSourceNode | null>(null);
  const streamRef = useRef<MediaStream | null>(null);
  const timerRef = useRef<number | null>(null);
  const animationRef = useRef<number | undefined>(undefined);

  const currentStep = testSteps[session.currentStep];
  
  // currentStepì´ undefinedì¸ ê²½ìš°ë¥¼ ë°©ì§€
  if (!currentStep) {
    return (
      <Box sx={{ maxWidth: 600, mx: 'auto', p: 3, textAlign: 'center' }}>
        <Typography variant="h5" color="error">
          í…ŒìŠ¤íŠ¸ ë‹¨ê³„ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.
        </Typography>
        <Button
          variant="contained"
          onClick={handleCancel}
          sx={{ mt: 2 }}
        >
          í…ŒìŠ¤íŠ¸ ì·¨ì†Œ
        </Button>
      </Box>
    );
  }

  // ì˜¤ë””ì˜¤ ë¶„ì„ ì‹œì‘
  const startAudioAnalysis = useCallback(async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: { echoCancellation: true, noiseSuppression: true, sampleRate: 44100 }
      });
      
      streamRef.current = stream;
      const audioContext = new (window.AudioContext || (window as any).webkitAudioContext)();
      audioContextRef.current = audioContext;
      
      const microphone = audioContext.createMediaStreamSource(stream);
      microphoneRef.current = microphone;
      
      const analyser = audioContext.createAnalyser();
      analyser.fftSize = 256;
      analyser.smoothingTimeConstant = 0.8;
      analyserRef.current = analyser;
      
      microphone.connect(analyser);
      
      // ë³¼ë¥¨ ë¶„ì„
      const dataArray = new Uint8Array(analyser.frequencyBinCount);
      const analyzeVolume = () => {
        if (analyser && isRecording) {
          analyser.getByteFrequencyData(dataArray);
          let sum = 0;
          for (let i = 0; i < dataArray.length; i++) {
            sum += dataArray[i];
          }
          const average = sum / dataArray.length;
          setVolume(Math.min(100, (average / 255) * 100));
          animationRef.current = requestAnimationFrame(analyzeVolume);
        }
      };
      
      analyzeVolume();
    } catch (err) {
      setError('ë§ˆì´í¬ ì ‘ê·¼ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë§ˆì´í¬ ê¶Œí•œì„ í™•ì¸í•´ì£¼ì„¸ìš”.');
    }
  }, [isRecording]);

  // ì˜¤ë””ì˜¤ ë¶„ì„ ì¤‘ì§€
  const stopAudioAnalysis = useCallback(() => {
    if (animationRef.current) {
      cancelAnimationFrame(animationRef.current);
      animationRef.current = undefined;
    }
    if (microphoneRef.current) {
      try {
        microphoneRef.current.disconnect();
      } catch (error) {
        console.warn('ë§ˆì´í¬ ì—°ê²° í•´ì œ ì¤‘ ì˜¤ë¥˜:', error);
      }
      microphoneRef.current = null;
    }
    if (audioContextRef.current) {
      try {
        if (audioContextRef.current.state !== 'closed') {
          audioContextRef.current.close();
        }
      } catch (error) {
        console.warn('ì˜¤ë””ì˜¤ ì»¨í…ìŠ¤íŠ¸ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜:', error);
      }
      audioContextRef.current = null;
    }
    if (streamRef.current) {
      streamRef.current.getTracks().forEach(track => track.stop());
      streamRef.current = null;
    }
    setVolume(0);
  }, []);

  // ë‹¤ìŒ ë‹¨ê³„ë¡œ
  const nextStep = useCallback(() => {
    // íƒ€ì´ë¨¸ ì •ë¦¬
    if (timerRef.current) {
      window.clearInterval(timerRef.current);
      timerRef.current = null;
    }
    
    if (session.currentStep < testSteps.length - 1) {
      setSession(prev => ({
        ...prev,
        currentStep: prev.currentStep + 1
      }));
      setCurrentTime(0);
    } else {
      // í…ŒìŠ¤íŠ¸ ì™„ë£Œ
      const overallScore = Math.floor(
        session.results.reduce((sum, result) => sum + result.score, 0) / session.results.length
      );
      
      setSession(prev => ({
        ...prev,
        isCompleted: true,
        overallScore,
        endTime: Date.now()
      }));
      
      onTestComplete(session.results);
    }
  }, [session.currentStep, session.results, onTestComplete]);

  // ë…¹ìŒ ë¶„ì„
  const analyzeRecording = useCallback(() => {
    setIsAnalyzing(true);
    
    // ì‹œë®¬ë ˆì´ì…˜ëœ ë¶„ì„ (ì‹¤ì œë¡œëŠ” ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ ë¶„ì„)
    setTimeout(() => {
      const result: VoiceTestResult = {
        stepId: currentStep.id,
        score: Math.floor(Math.random() * 40) + 60, // 60-100ì 
        data: {
          frequency: currentStep.type === 'range' ? Math.random() * 200 + 100 : undefined,
          stability: currentStep.type === 'sustain' ? Math.random() * 30 + 70 : undefined,
          accuracy: currentStep.type === 'melody' ? Math.random() * 25 + 75 : undefined,
          characteristics: {
            pitchVariation: Math.random() * 100,
            vibrato: Math.random() * 100,
            breathiness: Math.random() * 100,
            brightness: Math.random() * 100
          }
        },
        timestamp: Date.now()
      };
      
      setSession(prev => ({
        ...prev,
        results: [...prev.results, result]
      }));
      
      setIsAnalyzing(false);
      nextStep();
    }, 2000);
  }, [currentStep, nextStep]);

  // ë…¹ìŒ ì¤‘ì§€
  const stopRecording = useCallback(() => {
    setIsRecording(false);
    stopAudioAnalysis();
    
    if (timerRef.current) {
      window.clearInterval(timerRef.current);
      timerRef.current = null;
    }
    
    // ë¶„ì„ ì‹œì‘
    analyzeRecording();
  }, [stopAudioAnalysis, analyzeRecording]);

  // ë…¹ìŒ ì‹œì‘
  const startRecording = useCallback(async () => {
    try {
      setError(null);
      setIsRecording(true);
      setCurrentTime(0);
      
      await startAudioAnalysis();
      
      // íƒ€ì´ë¨¸ ì‹œì‘
      timerRef.current = window.setInterval(() => {
        setCurrentTime(prev => {
          const newTime = prev + 0.1;
          if (newTime >= currentStep.duration) {
            stopRecording();
            return currentStep.duration;
          }
          return newTime;
        });
      }, 100);
      
    } catch (err) {
      setError('ë…¹ìŒì„ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.');
      setIsRecording(false);
    }
  }, [currentStep.duration, startAudioAnalysis, stopRecording]);

  // í…ŒìŠ¤íŠ¸ ì·¨ì†Œ
  const handleCancel = useCallback(() => {
    stopAudioAnalysis();
    if (timerRef.current) {
      window.clearInterval(timerRef.current);
      timerRef.current = null;
    }
    onTestCancel();
  }, [stopAudioAnalysis, onTestCancel]);

  // ì»´í¬ë„ŒíŠ¸ ì–¸ë§ˆìš´íŠ¸ ì‹œ ì •ë¦¬
  useEffect(() => {
    return () => {
      stopAudioAnalysis();
      if (timerRef.current) {
        window.clearInterval(timerRef.current);
        timerRef.current = null;
      }
    };
  }, [stopAudioAnalysis]);

  const progress = (session.currentStep / testSteps.length) * 100;
  const timeProgress = (currentTime / currentStep.duration) * 100;

  return (
    <Box sx={{ maxWidth: 600, mx: 'auto', p: 3 }}>
      {/* í—¤ë” */}
      <Box sx={{ textAlign: 'center', mb: 4 }}>
        <Typography variant="h4" sx={{ fontWeight: 'bold', mb: 2 }}>
          ğŸ¤ ëª©ì†Œë¦¬ í…ŒìŠ¤íŠ¸
        </Typography>
        <Typography variant="body1" color="text.secondary">
          ë‹¹ì‹ ì˜ ìŒì—­ëŒ€ì™€ ìŒìƒ‰ì„ ë¶„ì„í•˜ì—¬ ë§ì¶¤ ì¶”ì²œì„ ì œê³µí•©ë‹ˆë‹¤
        </Typography>
      </Box>

      {/* ì „ì²´ ì§„í–‰ë¥  */}
      <Paper elevation={2} sx={{ p: 3, mb: 3 }}>
        <Box sx={{ display: 'flex', justifyContent: 'space-between', alignItems: 'center', mb: 2 }}>
          <Typography variant="h6" sx={{ fontWeight: 'bold' }}>
            ì§„í–‰ë¥ 
          </Typography>
          <Typography variant="body2" color="text.secondary">
            {session.currentStep + 1} / {testSteps.length}
          </Typography>
        </Box>
        <LinearProgress 
          variant="determinate" 
          value={progress} 
          sx={{ height: 8, borderRadius: 4 }}
        />
      </Paper>

      {/* í˜„ì¬ ë‹¨ê³„ */}
      <Card elevation={3} sx={{ mb: 3 }}>
        <CardContent sx={{ p: 4 }}>
          <Typography variant="h5" sx={{ fontWeight: 'bold', mb: 2, textAlign: 'center' }}>
            {currentStep.title}
          </Typography>
          <Typography variant="body1" sx={{ mb: 3, textAlign: 'center' }}>
            {currentStep.description}
          </Typography>
          
          <Paper elevation={1} sx={{ p: 3, mb: 3, backgroundColor: 'grey.50' }}>
            <Typography variant="body2" sx={{ fontWeight: 'bold', mb: 1 }}>
              ğŸ“‹ ì§€ì‹œì‚¬í•­:
            </Typography>
            <Typography variant="body2">
              {currentStep.instruction}
            </Typography>
          </Paper>

          {/* ë…¹ìŒ ì»¨íŠ¸ë¡¤ */}
          <Box sx={{ textAlign: 'center', mb: 3 }}>
            {!isRecording && !isAnalyzing && (
              <Button
                variant="contained"
                size="large"
                startIcon={<Mic />}
                onClick={startRecording}
                sx={{ minWidth: 200, height: 60, fontSize: '1.1rem' }}
              >
                ë…¹ìŒ ì‹œì‘
              </Button>
            )}
            
            {isRecording && (
              <Button
                variant="contained"
                color="error"
                size="large"
                startIcon={<MicOff />}
                onClick={stopRecording}
                sx={{ minWidth: 200, height: 60, fontSize: '1.1rem' }}
              >
                ë…¹ìŒ ì¤‘ì§€
              </Button>
            )}
            
            {isAnalyzing && (
              <Box sx={{ display: 'flex', flexDirection: 'column', alignItems: 'center', gap: 2 }}>
                <CircularProgress size={60} />
                <Typography variant="body1">
                  ìŒì„± ë¶„ì„ ì¤‘...
                </Typography>
              </Box>
            )}
          </Box>

          {/* ì‹œê°„ ì§„í–‰ë¥  */}
          {isRecording && (
            <Box sx={{ mb: 3 }}>
              <Box sx={{ display: 'flex', justifyContent: 'space-between', mb: 1 }}>
                <Typography variant="body2" color="text.secondary">
                  ë…¹ìŒ ì‹œê°„
                </Typography>
                <Typography variant="body2" color="text.secondary">
                  {currentTime.toFixed(1)}s / {currentStep.duration}s
                </Typography>
              </Box>
              <LinearProgress 
                variant="determinate" 
                value={timeProgress} 
                sx={{ height: 6, borderRadius: 3 }}
              />
            </Box>
          )}

          {/* ë³¼ë¥¨ í‘œì‹œ */}
          {isRecording && (
            <Box sx={{ mb: 3 }}>
              <Box sx={{ display: 'flex', justifyContent: 'space-between', mb: 1 }}>
                <Typography variant="body2" color="text.secondary">
                  ìŒëŸ‰
                </Typography>
                <Typography variant="body2" color="text.secondary">
                  {Math.round(volume)}%
                </Typography>
              </Box>
              <LinearProgress 
                variant="determinate" 
                value={volume} 
                color={volume > 50 ? 'success' : volume > 20 ? 'warning' : 'error'}
                sx={{ height: 6, borderRadius: 3 }}
              />
            </Box>
          )}

          {/* ì—ëŸ¬ ë©”ì‹œì§€ */}
          {error && (
            <Alert severity="error" sx={{ mb: 3 }}>
              {error}
            </Alert>
          )}
        </CardContent>
      </Card>

      {/* ê²°ê³¼ í‘œì‹œ */}
      {session.results.length > 0 && (
        <Paper elevation={2} sx={{ p: 3, mb: 3 }}>
          <Typography variant="h6" sx={{ fontWeight: 'bold', mb: 2 }}>
            ğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼
          </Typography>
          <Box sx={{ display: 'flex', flexDirection: 'column', gap: 1 }}>
            {session.results.map((result, index) => (
              <Box key={`${result.stepId}-${index}-${result.timestamp}`} sx={{ display: 'flex', alignItems: 'center', gap: 2 }}>
                <CheckCircle color="success" />
                <Typography variant="body2" sx={{ flex: 1 }}>
                  {testSteps[index]?.title || result.stepId}
                </Typography>
                <Typography variant="body2" sx={{ fontWeight: 'bold' }}>
                  {result.score}ì 
                </Typography>
              </Box>
            ))}
          </Box>
        </Paper>
      )}

      {/* ì·¨ì†Œ ë²„íŠ¼ */}
      <Box sx={{ textAlign: 'center' }}>
        <Button
          variant="outlined"
          color="error"
          onClick={handleCancel}
          startIcon={<Cancel />}
        >
          í…ŒìŠ¤íŠ¸ ì·¨ì†Œ
        </Button>
      </Box>
    </Box>
  );
};

export default VoiceTestGame;
