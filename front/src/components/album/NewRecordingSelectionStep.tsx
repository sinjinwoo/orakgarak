/**
 * New Recording Selection Stage with Drag & Drop
 * ë“œë˜ê·¸ì•¤ë“œë¡­ì´ í¬í•¨ëœ ìƒˆë¡œìš´ ë…¹ìŒ ì„ íƒ ë‹¨ê³„
 */

import React, { useState, useCallback } from 'react';
import {
  DndContext,
  DragEndEvent,
  DragOverEvent,
  PointerSensor,
  KeyboardSensor,
  useSensor,
  useSensors,
  closestCenter,
} from '@dnd-kit/core';
import LibraryPanel from './LibraryPanel';
import TrackCanvas from './TrackCanvas';
import StepHeader from './StepHeader';
import { type Recording } from '../../types/recording';
import { Music } from 'lucide-react';

interface Track extends Recording {
  order: number;
  // UIì—ì„œ í•„ìš”í•œ ì¶”ê°€ í•„ë“œë“¤
  title?: string;
  artist?: string;
  durationSec?: number;
}

interface NewRecordingSelectionStepProps {
  recordings: Recording[];
  selectedRecordings: string[];
  loading?: boolean;
  error?: string | null;
  onToggleRecording: (recordingId: string) => void;
  onAddToast?: (toast: { type: 'success' | 'error' | 'warning' | 'info'; message: string }) => void;
  className?: string;
}

const NewRecordingSelectionStep: React.FC<NewRecordingSelectionStepProps> = ({
  recordings,
  selectedRecordings,
  loading = false,
  error = null,
  onToggleRecording,
  onAddToast,
  className = '',
}) => {
  const [tracks, setTracks] = useState<Track[]>([]);
  const [currentPlayingId, setCurrentPlayingId] = useState<string | null>(null);
  const audioRef = React.useRef<HTMLAudioElement | null>(null);

  const normalizeId = (id: string | number): string => String(id).trim();

  // Drag and drop sensors
  const sensors = useSensors(
    useSensor(PointerSensor, {
      activationConstraint: {
        distance: 8,
      },
    }),
    useSensor(KeyboardSensor)
  );

  React.useEffect(() => {
    const normalizedSelectedIds = new Set(selectedRecordings.map(normalizeId));
    const newTracks = recordings
      .filter(recording => normalizedSelectedIds.has(normalizeId(recording.id)))
      .map((recording, index) => ({
        ...recording,
        order: index + 1,
        durationSec: recording.duration || 0,
      }));
    setTracks(newTracks);
  }, [recordings, selectedRecordings]);

  // Handle track reordering
  const handleTracksReorder = useCallback((reorderedTracks: Track[]) => {
    setTracks(reorderedTracks);
    // Update selected recordings order
    const newSelectedRecordings = reorderedTracks.map(track => track.id);
    // This would need to be implemented in the parent component to maintain order
    // For now, we'll just keep the tracks state in sync
  }, []);

  const handleTrackRemove = useCallback((trackId: string) => {
    onToggleRecording(normalizeId(trackId));

    onAddToast?.({
      type: 'info',
      message: 'íŠ¸ë™ì´ ì œê±°ë˜ì—ˆìŠµë‹ˆë‹¤.',
    });
  }, [onToggleRecording, onAddToast]);

  const handleTrackAdd = useCallback((recording: Recording) => {
    if (selectedRecordings.length >= 10) {
      onAddToast?.({
        type: 'warning',
        message: 'ìµœëŒ€ 10ê³¡ê¹Œì§€ë§Œ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.',
      });
      return;
    }

    onToggleRecording(normalizeId(recording.id));
    onAddToast?.({
      type: 'success',
      message: `"${recording.song?.title || ''}"ì´(ê°€) ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.`,
    });
  }, [selectedRecordings.length, onToggleRecording, onAddToast]);

  // ì¬ìƒ/ì¼ì‹œì •ì§€ êµ¬í˜„ (recording.url ì‚¬ìš©)
  const handlePlayToggle = useCallback((recordingId: string) => {
    const normalize = (id: string | number) => String(id);
    const recording = recordings.find(r => normalize(r.id) === normalize(recordingId));
    if (!recording) return;

    const isPlayable = !!recording.url && (!recording.urlStatus || recording.urlStatus === 'SUCCESS');
    if (!isPlayable) {
      // ì¬ìƒ ë¶ˆê°€ ìƒíƒœë©´ ê·¸ëƒ¥ í† ê¸€í•˜ì§€ ì•ŠìŒ
      return;
    }

    // ì˜¤ë””ì˜¤ ì¸ìŠ¤í„´ìŠ¤ ì¤€ë¹„
    if (!audioRef.current) {
      audioRef.current = new Audio();
      audioRef.current.crossOrigin = 'anonymous';
      audioRef.current.preload = 'auto';
      audioRef.current.addEventListener('ended', () => {
        setCurrentPlayingId(null);
      });
      audioRef.current.addEventListener('error', () => {
        setCurrentPlayingId(null);
      });
    }

    const audio = audioRef.current;

    // ê°™ì€ íŠ¸ë™ì„ ë‹¤ì‹œ ëˆ„ë¥´ë©´ ì •ì§€
    if (currentPlayingId === recordingId) {
      try {
        audio.pause();
        audio.currentTime = 0;
      } catch {}
      setCurrentPlayingId(null);
      return;
    }

    // ìƒˆë¡œìš´ íŠ¸ë™ ì¬ìƒ
    try {
      audio.pause();
      audio.currentTime = 0;
    } catch {}

    audio.src = recording.url!;
    // content_type íŒíŠ¸ê°€ ìˆìœ¼ë©´ type ì§€ì • (ì¼ë¶€ ë¸Œë¼ìš°ì € í˜¸í™˜ì„± í–¥ìƒ)
    // HTMLAudioElementì—ëŠ” type ì†ì„±ì´ ì—†ìœ¼ë¯€ë¡œ, srcë§Œ ì„¤ì •

    // ì¦‰ì‹œ ì¬ìƒ (ì‚¬ìš©ì ì œìŠ¤ì²˜ ë‚´ì—ì„œ í˜¸ì¶œë¨)
    audio.play()
      .then(() => {
        setCurrentPlayingId(recordingId);
      })
      .catch(() => {
        setCurrentPlayingId(null);
      });
  }, [recordings, currentPlayingId]);

  // ì–¸ë§ˆìš´íŠ¸ ì‹œ ì •ë¦¬
  React.useEffect(() => {
    return () => {
      if (audioRef.current) {
        try {
          audioRef.current.pause();
        } catch {}
        audioRef.current = null;
      }
    };
  }, []);

  const handleDragEnd = useCallback((event: DragEndEvent) => {
    const { active, over } = event;

    if (!over) return;

    if (over.id === 'track-canvas' && !tracks.find(t => normalizeId(t.id) === normalizeId(active.id))) {
      const recording = recordings.find(r => normalizeId(r.id) === normalizeId(active.id));
      if (recording && !selectedRecordings.some(id => normalizeId(id) === normalizeId(recording.id))) {
        handleTrackAdd(recording);
      }
    }
  }, [tracks, recordings, selectedRecordings, handleTrackAdd]);

  const handleDragOver = useCallback((event: DragOverEvent) => {
    // Handle drag over events if needed
  }, []);

  return (
    <DndContext
      sensors={sensors}
      collisionDetection={closestCenter}
      onDragEnd={handleDragEnd}
      onDragOver={handleDragOver}
    >
      <div className={`h-full ${className}`}>
        {/* Header */}
        <StepHeader
          title="ë…¹ìŒ ì„ íƒ"
          description="ì•¨ë²”ì— í¬í•¨í•  ë…¹ìŒì„ ì„ íƒí•˜ê³  ìˆœì„œë¥¼ ì¡°ì •í•´ë³´ì„¸ìš”. ë“œë˜ê·¸ì•¤ë“œë¡­ìœ¼ë¡œ ì‰½ê²Œ ì¶”ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
          icon={<Music className="w-6 h-6 text-fuchsia-400" />}
        />

        {/* Two-column layout */}
        <div className="grid grid-cols-[400px_1fr] gap-6 h-[calc(100%-120px)]">
          {/* Left: Library Panel */}
          <LibraryPanel
            recordings={recordings}
            selectedRecordings={selectedRecordings}
            onToggleRecording={(id) => onToggleRecording(normalizeId(id))}
            onPlayRecording={handlePlayToggle}
            currentPlayingId={currentPlayingId}
            loading={loading}
            error={error}
          />

          {/* Right: Track Canvas */}
          <TrackCanvas
            tracks={tracks}
            onTracksReorder={handleTracksReorder}
            onTrackRemove={handleTrackRemove}
            onTrackAdd={handleTrackAdd}
            onPlayTrack={handlePlayToggle}
            currentPlayingId={currentPlayingId}
            maxTracks={10}
          />
        </div>

        {/* Quick Stats */}
        <div className="mt-4 flex items-center justify-between text-sm text-white/60">
          <div className="flex items-center gap-4">
            <span>ì„ íƒëœ íŠ¸ë™: {new Set(selectedRecordings).size}/10</span>
            <span>
              ì´ ê¸¸ì´: {Math.floor(tracks.reduce((sum, track) => sum + (track.duration || track.durationSec || 0), 0) / 60)}ë¶„
            </span>
          </div>
          <div className="text-xs text-white/40">
            ğŸ’¡ íŒ: íŠ¸ë™ì„ ë“œë˜ê·¸í•´ì„œ ìˆœì„œë¥¼ ë°”ê¿€ ìˆ˜ ìˆìŠµë‹ˆë‹¤
          </div>
        </div>
      </div>
    </DndContext>
  );
};

export default NewRecordingSelectionStep;